{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "wK3zJ_YCh4q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7WUgi4EiEd7",
        "outputId": "6e8842ce-1e3f-4b83-bd5a-35e51d77f0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'best_model_lstm.keras'\n",
        "tokenizer_path = 'label_encoder.pickle'\n",
        "label_encoder_path = 'tokenizer.pickle'"
      ],
      "metadata": {
        "id": "Wyv_vJiniI9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loading model from {model_path}...\")\n",
        "try:\n",
        "    loaded_model = tf.keras.models.load_model(model_path)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    loaded_model = None # Set to None if loading fails\n",
        "\n",
        "\n",
        "# Load Tokenizer\n",
        "print(f\"Loading tokenizer from {tokenizer_path}...\")\n",
        "try:\n",
        "    # Corrected: Load tokenizer from 'tokenizer.pickle' and assign to loaded_tokenizer\n",
        "    with open(label_encoder_path, 'rb') as handle: # Assuming label_encoder_path points to tokenizer.pickle\n",
        "        loaded_tokenizer = pickle.load(handle)\n",
        "    print(\"Tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "    loaded_tokenizer = None\n",
        "\n",
        "\n",
        "# Load Label Encoder\n",
        "print(f\"Loading label encoder from {label_encoder_path}...\")\n",
        "try:\n",
        "    # Corrected: Load label encoder from 'label_encoder.pickle' and assign to loaded_label_encoder\n",
        "    with open(tokenizer_path, 'rb') as handle: # Assuming tokenizer_path points to label_encoder.pickle\n",
        "        loaded_label_encoder = pickle.load(handle)\n",
        "    print(\"Label encoder loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading label encoder: {e}\")\n",
        "    loaded_label_encoder = None\n",
        "\n",
        "# Pastikan semua objek berhasil dimuat sebelum melanjutkan\n",
        "if loaded_model and loaded_tokenizer and loaded_label_encoder:\n",
        "    print(\"\\nAll necessary components loaded.\")\n",
        "else:\n",
        "    print(\"\\nFailed to load one or more components. Please check file paths and ensure files exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLU9o3a0fkX-",
        "outputId": "7bf4e53d-7829-465f-cb77-39681d20b749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from best_model_lstm.keras...\n",
            "Model loaded successfully.\n",
            "Loading tokenizer from label_encoder.pickle...\n",
            "Tokenizer loaded successfully.\n",
            "Loading label encoder from tokenizer.pickle...\n",
            "Label encoder loaded successfully.\n",
            "\n",
            "All necessary components loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PX7iXgOiUf0",
        "outputId": "ed168d70-9ede-4d15-cdc8-8a6a71a4369b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji"
      ],
      "metadata": {
        "id": "m-QJosoxicrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inisialisasi lemmatizer (jika digunakan saat training)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords_inggris = set(stopwords.words('english')) # Pastikan set stopwords sama\n",
        "\n",
        "# Fungsi untuk menghapus emoji (gunakan library emoji jika digunakan saat training)\n",
        "# Jika Anda tidak menggunakan library emoji saat training, hapus atau sesuaikan fungsi ini\n",
        "\n",
        "def remove_emoji(text):\n",
        "    return emoji.replace_emoji(text, replace='')\n",
        "\n",
        "# Fungsi untuk menghapus angka\n",
        "def hapus_angka(teks):\n",
        "    teks_tanpa_angka = ''.join([char for char in teks if not char.isdigit()])\n",
        "    return teks_tanpa_angka\n",
        "\n",
        "# Fungsi untuk menghapus tanda baca\n",
        "def remove_punctuation(text):\n",
        "    punctuation_set = set(string.punctuation)\n",
        "    text_without_punctuation = ''.join(char for char in text if char not in punctuation_set)\n",
        "    return text_without_punctuation\n",
        "\n",
        "# Fungsi utama preprocessing\n",
        "def preprocess_text_for_inference(text):\n",
        "    # Case folding\n",
        "    text = text.lower()\n",
        "    # Menghapus white space\n",
        "    text = text.strip()\n",
        "    # Menghapus emoji (gunakan fungsi yang sudah ada)\n",
        "    text = remove_emoji(text)\n",
        "    # Menghapus angka (gunakan fungsi yang sudah ada)\n",
        "    text = hapus_angka(text)\n",
        "    # Menghapus special character (gunakan fungsi yang sudah ada)\n",
        "    text = remove_punctuation(text)\n",
        "    # Stopword removal and Tokenizing (gunakan fungsi yang sudah ada)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens_cleaned = [word for word in tokens if word.lower() not in stopwords_inggris]\n",
        "    # Lemmatization (menggunakan fungsi yang sudah ada)\n",
        "    text_lemmatized = lemmatizer.lemmatize(' '.join(tokens_cleaned))\n",
        "\n",
        "    return text_lemmatized\n",
        "\n",
        "print(\"Preprocessing functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrgEI69HhytH",
        "outputId": "279d4aaf-146b-4c3e-ad04-8c6cf58c424b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pastikan max_length sama dengan yang digunakan saat pelatihan\n",
        "max_length = 100 # <-- Ganti dengan nilai max_length yang benar dari notebook training Anda\n",
        "\n",
        "def predict_mental_health_status(input_text, model, tokenizer, max_length, label_encoder):\n",
        "    if not model or not tokenizer or not label_encoder:\n",
        "        print(\"Error: Model, Tokenizer, or Label Encoder not loaded.\")\n",
        "        return None, None\n",
        "\n",
        "    # Add print statements to check the types of tokenizer and label_encoder\n",
        "    print(f\"Type of tokenizer inside function: {type(tokenizer)}\")\n",
        "    print(f\"Type of label_encoder inside function: {type(label_encoder)}\")\n",
        "\n",
        "    # Preprocess the input text using the defined functions\n",
        "    cleaned_text = preprocess_text_for_inference(input_text)\n",
        "    print(f\"Cleaned text for inference: {cleaned_text}\")\n",
        "\n",
        "    # Tokenize and pad the text\n",
        "    # tokenizer.texts_to_sequences expects a list of strings\n",
        "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "    # Make prediction\n",
        "    predictions_probs = model.predict(padded_sequence)\n",
        "    # Get the predicted class index\n",
        "    predicted_class_index = np.argmax(predictions_probs, axis=1)[0]\n",
        "\n",
        "    # Get the predicted class name using the label encoder\n",
        "    # Ensure the index is within the bounds of label_encoder.classes_\n",
        "    if 0 <= predicted_class_index < len(label_encoder.classes_):\n",
        "         predicted_status = label_encoder.classes_[predicted_class_index]\n",
        "    else:\n",
        "         # Handle potential unexpected index if necessary\n",
        "         predicted_status = \"Unknown Status (Index out of bounds)\"\n",
        "\n",
        "\n",
        "    return predicted_status, predictions_probs[0]\n",
        "\n",
        "print(\"Prediction function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gy2KKZDiR2i",
        "outputId": "af28f02d-ea7e-4927-a70b-eeb49b3bff42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# --- Contoh Penggunaan Fungsi Prediksi ---\n",
        "input_statement = \"im having trouble sleeping because im so stress.\"\n",
        "\n",
        "# Pastikan loaded_model, loaded_tokenizer, dan loaded_label_encoder sudah berhasil dimuat\n",
        "if loaded_model and loaded_tokenizer and loaded_label_encoder:\n",
        "    predicted_status_result, probabilities = predict_mental_health_status(\n",
        "        input_statement,\n",
        "        loaded_model,\n",
        "        loaded_tokenizer, # Corrected: Pass loaded_tokenizer here\n",
        "        max_length, # Gunakan max_length yang sudah didefinisikan\n",
        "        loaded_label_encoder\n",
        "    )\n",
        "\n",
        "    print(f\"\\nInput Statement: \\\"{input_statement}\\\"\")\n",
        "    print(f\"Predicted Status: {predicted_status_result}\")\n",
        "    print(f\"Prediction Probabilities:\")\n",
        "    # Untuk melihat probabilitas dengan nama kelas:\n",
        "    if probabilities is not None:\n",
        "        for i, prob in enumerate(probabilities):\n",
        "            # Pastikan indeks kelas valid\n",
        "            if i < len(loaded_label_encoder.classes_):\n",
        "                 print(f\"  {loaded_label_encoder.classes_[i]}: {prob:.4f}\")\n",
        "            else:\n",
        "                 print(f\"  Unknown Class {i}: {prob:.4f}\")\n",
        "else:\n",
        "    print(\"\\nCannot perform prediction because model or preprocessing objects were not loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aop6mvHBipC-",
        "outputId": "1f0eca55-9a82-4d53-d36c-25098f208d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of tokenizer inside function: <class 'keras.src.legacy.preprocessing.text.Tokenizer'>\n",
            "Type of label_encoder inside function: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
            "Cleaned text for inference: im trouble sleeping im stress\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\n",
            "Input Statement: \"im having trouble sleeping because im so stress.\"\n",
            "Predicted Status: Stress\n",
            "Prediction Probabilities:\n",
            "  Anxiety: 0.1931\n",
            "  Bipolar: 0.0030\n",
            "  Depression: 0.0039\n",
            "  Normal: 0.3458\n",
            "  Personality disorder: 0.0005\n",
            "  Stress: 0.4522\n",
            "  Suicidal: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_rekomendasi = pd.read_csv ('mentalhealthtreatment.csv')"
      ],
      "metadata": {
        "id": "i1PRnqXZnQ1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_recommendations_by_status(status, recommendation_df):\n",
        "    filtered_df = recommendation_df[recommendation_df['status'] == status]\n",
        "    recommendations = filtered_df['treatment'].tolist()\n",
        "    return recommendations\n",
        "\n",
        "predicted_status_example = predicted_status_result\n",
        "\n",
        "recommendations_for_status = get_recommendations_by_status(\n",
        "    predicted_status_example,\n",
        "    df_rekomendasi\n",
        ")\n",
        "\n",
        "print(f\"Rekomendasi untuk status '{predicted_status_example}':\")\n",
        "if recommendations_for_status:\n",
        "    for i, rec in enumerate(recommendations_for_status):\n",
        "        print(f\"- {rec}\")\n",
        "else:\n",
        "    print(f\"Tidak ada rekomendasi yang ditemukan untuk status '{predicted_status_example}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcdT7BUTlSIQ",
        "outputId": "41b5c3da-ec6b-4e17-bc60-b20d07d7e402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rekomendasi untuk status 'Stress':\n",
            "- Get more physical activity \n",
            "- Eat a balanced diet \n",
            "- Minimize screen time\n",
            "- Going for a walk outside\n",
            "- Taking a bath\n",
            "- Reading a good book\n",
            "- Exercising \n",
            "- Stretching before bed\n",
            "- Getting a massage\n",
            "- Practicing a hobby\n",
            "- Using a diffuser with calming scents\n",
            "- Try journaling\n",
            "- Reduce your caffeine intake\n",
            "- Spend time with loved ones\n",
            "- Create boundaries and learn to say no\n",
            "- Avoid procrastination\n",
            "- Spend time in nature\n",
            "- Practice deep breathing\n",
            "- Spend time with a pet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_Loc7fsp-0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}